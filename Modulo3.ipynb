{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Módulo 3\n",
        "author: |\n",
        "  | Antonio Otal\n",
        "  | contacto: aotalpalacin@gmail.com\n",
        "lang: es\n",
        "execute:\n",
        "  echo: false\n",
        "format:\n",
        "  pdf:\n",
        "    page-layout: full\n",
        "    code-fold: true\n",
        "    number-sections: true\n",
        "    colorlinks: true\n",
        "    geometry:\n",
        "      - top=10mm\n",
        "      - left=10mm\n",
        "      - bottom=10mm\n",
        "      - heightrounded\n",
        "---"
      ],
      "id": "8277a7de"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Describa brevemente cada uno de los pasos que se han seguido hasta la evaluación del modelo.\n",
        "\n",
        "Los pasos que se han seguido hasta la evaluación del modelo han sido los siguientes:\n",
        "\n",
        "## Importación de las librerías necesarias\n",
        "\n",
        " Librerías de python que necesitaremos, entre ellas algunas de algebra (numpy), visualización (matplotlib, opencv...), machine learning (scikit-learn) o de deep learning (tensorflow y keras), tablas (pandas), etc.  \n",
        "\n",
        "## Obtención de los datos \n",
        "\n",
        "Se descargaron los datos anotados de un repositorio remoto, en nuestro  caso de una cuenta de Google Drive. Dichos datos ya venían separados en los tres bloques para componer nuestro modelo, en un directorio cada uno de ellos.\n",
        "\n",
        "        - Entrenamiento (train)\n",
        "        - Validación (val)\n",
        "        - Comprobación (test)\n",
        "\n",
        "A su vez, dentro de cada uno de los directorios anteriores hay en cada uno de ellos uno llamado *normal* y otro *opacity*. Dentro de ellos se encuantran los ficheros de imagen de pulmones con neumonía y sin ella respectivamente. Mediante esta estructura se ha hecho la anotación de imágenes, las cuales vienen el formato jpeg monocromático con una profundidad de 8 bits.\n",
        "\n",
        "## Visualización de datos\n",
        "\n",
        "## Definición de la red neuronal y de los hiperparámetros** \n",
        "\n",
        "## Entrenamiento y validación\n",
        "Entrenamos nuestra red mediante en conjunto *train* y lo validamos con *val*.\n",
        "\n",
        "# ¿Qué tipo de algoritmo de IA estamos programando?\n",
        "\n",
        "En este caso se definió una red neuronal convolucional.\n",
        "\n",
        "# En este caso ya tenemos los datos separados en datasets de entrenamiento,validación y test. ¿Qué otra herramienta podríamos usar si este no fuera el caso?\n",
        "\n",
        "En este caso se nos sugiere utilizar la librería *scikit-learn*, [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
        "\n",
        "# Describa la arquitectura de la red que se ha programado.\n",
        "\n",
        "La red cuenta con 3 capas convolucionales (las que extraerán las *features*), dos capas densas la primera con una capa de activación *relu* y otra *sigmoid*.\n",
        "\n",
        "\n",
        "# ¿Qué función de activación hemos usado en cada una de las capas convolucionales?¿Por qué se ha usado?\n",
        "\n",
        "En las capas convolucionales hemos utilizado la función de activación *relu*. Las función de activación es lo que hace que la red neuronal *escape*  del comportamiento lineal, siendo así posible que la red describa funciones no lineales. \n",
        "\n",
        "# ¿Qué nos indica la matriz de confusión con respecto a la sensibilidad y especificidad? ¿Y la curva ROC?\n",
        "\n",
        "La sensibilidad, también conocida como la tasa de verdaderos positivos, mide la habilidad del modelo para detectar correctamente una clase específica. Mientras que la especificidad describe la capacidad del modelo para evitar falsos positivos. Como la matriz de confusión muestra la cantidad de veces que el modelo ha acertado y fallado para cada una de las clases, es una buena herramienta para evaluar ambas propiedades del modelo. Por otro lado la curva ROC es poner en una gráfica los dos parámetros mencionados(X especificidad, Y sensibilidad). Por lo tanto la forma de dicha curva determinará la idoneidad del modelo. Cuanto más se acerque a la bisectriz, peor será el modelo.\n",
        "\n",
        "\n",
        "# Ejecute el modelo con alguna variación (por ejemplo, añadiendo algún parámetro de regularización, cambiando la función de activación de alguna de las capas, modificando alguna capa, modificando algún hiperparámetro, etc.). Explique qué variación/es ha introducido y cómo cambia el resultado del modelo, adjuntando además una imagen de la matriz de confusión y la curva ROC.\n",
        "\n",
        "He añadido una capa densa extra y el modelo prácticamente no vería, incluso empeora. En la *época* 2 hace un movimiento extraño con los datos de validación. Además tanto la matriz \n",
        "de confusión como la curva ROC arrojan peores resultados al complicar el modelo.\n"
      ],
      "id": "8e5abc6d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-charts\n",
        "#| fig-cap: Comparativa entre ambas configuraciones de la red\n",
        "#| fig-subcap: \n",
        "#|   - \"Curvas de aprendizaje\"\n",
        "#|   - \"Matrices de confusión\"\n",
        "#|   - \"Curvas ROC\"\n",
        "#| layout-nrow: 3\n",
        "\n",
        "import numpy as np # librería para álgebra lineal\n",
        "import matplotlib.pyplot as plt #para realizar los gráficos\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_curve,auc,classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "def plot_history(model1, model2):\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 2), sharey=True)\n",
        "    model1.plot(ax=ax[0], grid=True)\n",
        "    ax[0].legend(prop={'size': 5})\n",
        "    model2.plot(ax=ax[1], grid=True)\n",
        "    ax[1].legend(prop={'size': 5})\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "\n",
        "def plot_roc_curve(ground_truth1, probability1, ground_truth2, probability2):\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 2), sharey=True)\n",
        "\n",
        "    for i, (ground_truth, probability) in enumerate(zip([ground_truth1, ground_truth2], [probability1, probability2])):\n",
        "        fpr, tpr, threshold_roc = roc_curve(ground_truth, probability)\n",
        "        sens = tpr; esp = fpr\n",
        "        ax[i].plot(esp, sens); ax[i].set_ylabel('Sensitivity'); ax[i].set_xlabel('1-Especificity')\n",
        "        ax[i].plot([0, 1], [0, 1], 'k--')\n",
        "        ax[i].plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % ('Pneumonia', auc(fpr, tpr)))\n",
        "        ax[i].legend()\n",
        "    plt.plot()\n",
        "    return\n",
        "\n",
        "\n",
        "original = pd.read_csv('datos/Original/original.csv')\n",
        "modificado = pd.read_csv('datos/CapaDensaExtra/modificado.csv')\n",
        "plot_history(original, modificado)\n",
        "\n",
        "# Load the data\n",
        "original_classes = np.loadtxt('datos/Original/test_generator.classes.txt')\n",
        "original_y_pred = np.loadtxt('datos/Original/y_pred.txt')\n",
        "mod_classes = np.loadtxt('datos/CapaDensaExtra/test_generator.classes.txt')\n",
        "mod_y_pred = np.loadtxt('datos/CapaDensaExtra/y_pred.txt')\n",
        "\n",
        "# Create a figure and subplots\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
        "fig.subplots_adjust(wspace=1, hspace=0.1)\n",
        "\n",
        "# Create a list of the confusion matrices to plot\n",
        "confusion_matrices = [(original_classes, original_y_pred), (mod_classes, mod_y_pred)]\n",
        "\n",
        "# Loop over the confusion matrices and plot each one\n",
        "for i, (classes, y_pred) in enumerate(confusion_matrices):\n",
        "    cm = confusion_matrix(classes, y_pred)\n",
        "    display=ConfusionMatrixDisplay(confusion_matrix=cm).plot(ax=ax[i])\n",
        "\n",
        "# Adjust the layout of the plot\n",
        "fig.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "predicciones_origin=np.loadtxt('datos/Original/predicciones.txt')\n",
        "predicciones_mod=np.loadtxt('datos/CapaDensaExtra/predicciones.txt')\n",
        "\n",
        "plot_roc_curve(original_classes, predicciones_origin, mod_classes, predicciones_mod)"
      ],
      "id": "52c9d697",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "quarto",
      "language": "python",
      "display_name": "Quarto"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}